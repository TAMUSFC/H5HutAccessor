"""
    Utilities for dealing with H5Hut files generated by OPAL
"""
import os
import pathlib
from datetime import datetime
from functools import lru_cache

import h5py
import numpy as np
from scipy.signal import argrelmin
from matplotlib import pyplot as plt
from matplotlib.gridspec import GridSpec
from matplotlib.colorbar import Colorbar

from .analysis_helpers import in_sector


class H5HutAccessor():
    r"""
    Loads an H5Hut file and stores the data in more useful numpy arrays.

    Parameters
    ----------
    fn : str
        path to the H5Hut file to process
    stride : int, optional
        stepsize (default: 1) between adjacent steps to load. Useful if the 
        user wants to examine a very fine file without using ALL the 
        temporal resolution.
    minstep : int, optional
        phase dump (not integrator!) step (default: 0) to begin processing 
        from
    maxstep : int, optional 
        maximum phase dump (not integrator!) step (default: -1) to process
    steps : sequence of ints, optional
        sequence of step indices to load. If this argument is given, `minstep,
        maxstep, stride` are all ignored!
    maxparts : int, optional
        max number of particles to consider on each step. This is the same
        as only taking the first `maxparts` columns in an un-filtered 
        instance, and is meant for quickly loading files with lots of
        particles.

    Attributes
    ----------
    t : float
        global time (sec)
    reftheta : float
        reference angle for each step (deg)
    refs : float
        reference axial distance for each step (m)
    refx, refy, refz : float
        reference position for each step (m)
    refpx, refpy, refpz : float
        reference momentum for each step (beta*gamma)
    refT : float
        reference energy for each step (MeV)
    Bref : float ndarray with shape (Nstep, 3)
        Reference magnetic field (T)
    Eref : float ndarray with shape (Nstep, 3)
        Reference electric field (MV/m)
    x, y, z : float ndarray with shape (Nstep, Nparticles)
        spatial coordinates (global frame) of all particles (m)
    px, py, pz : float ndarray with shape (Nstep, Nparticles)
        momentum coordinates (global frame) of all particles (units of beta*gamma)
    unitinfo : dict
        all unit information stored on the head of the H5Hut file

    Notes
    -----
    The HDF5 file will be closed after initialization.

    The units given above are typical for my use case, but check the `unitinfo`
    property to be sure.

    OPAL uses the symbol # to indicate special characters, which seem to correspond 
    to the equivalent LaTeX commands, i.e.:
        #varepsilon -> $\varepsilon$
        #beta -> $\beta$
        etc...
    """

    def __init__(self, fn, stride=1, minstep=0, maxstep=None, steps=None, maxparts=None):
        self._fn = str(pathlib.Path(fn).resolve())
        self._h5 = h5file = h5py.File(self._fn, 'r')
        self.modified_time = datetime.fromtimestamp(int(os.stat(fn).st_mtime))
        filesteps = [k for k in h5file.keys() if k.startswith('Step#')]
        filesteps.sort(key=lambda n: int(n.split('#')[-1]))

        if steps:  # user has provided a list of step indices
            filesteps = [filesteps[idx] for idx in steps]
        elif minstep or maxstep or stride:  # user has provided striding information
            filesteps = filesteps[minstep:maxstep:stride]

        self.steps = filesteps

        Nstep = len(self.steps)

        assert h5file[self.steps[0]].attrs['NumBunch'] == 1, "Only single-bunch files are supported"

        # N.B. this is NOT correct if we inject additional beam after the first saved step!
        pid0 = h5file[self.steps[0]]['id']
        Npart = pid0.size
        if maxparts:
            Npart = min(Npart, maxparts)
        pid0 = pid0[:Npart]
        
        # iterating steps is relatively expensive, so let's establish arrays to store data
        # the default datatype is np.float64 (8 bytes per value), so 8 * (Nstep*(3+6+6*Npart)) bytes total
        # (~ 80 MB for 1000 particles and 1667 steps; attrs data should be kbytes worth at O(Nstep))
        for refarray in ('refs', 'refr', 'reftheta', 'refz', 
                         'refpr', 'refpt', 'refpz', 't',
                         'refT'):
            setattr(self, refarray, np.full((Nstep,), np.nan))
        for refarray in ('Bref', 'Eref', 'emit_norm', 'emit_geom'):
            setattr(self, refarray, np.full((Nstep, 3), np.nan))

        # initialize all values to NaN 
        self._particledata = np.full((Nstep, Npart, 6), np.nan)

        # store a bunch of unit information
        self.unitinfo = {k: v for k,v in h5file.attrs.items() if 'unit' in k.lower()}
        for stepnum, step in enumerate(self.steps):
            try:
                s = h5file[step]
                self.refs[stepnum]          = s.attrs['SPOS'][()]
                self.t[stepnum]             = s.attrs['TIME'][()]
                self.refr[stepnum]          = s.attrs['REFR'][()] * 1e-3 # mm -> m
                self.reftheta[stepnum]      = s.attrs['REFTHETA'][()]
                self.refz[stepnum]          = s.attrs['REFZ'][()] * 1e-3 # mm -> m
                self.refpr[stepnum]         = s.attrs['REFPR'][()]
                self.refpt[stepnum]         = s.attrs['REFPT'][()]
                self.refpz[stepnum]         = s.attrs['REFPZ'][()]
                self.refT[stepnum]          = s.attrs['ENERGY'][()]
                # normalized emittance - m rad
                # the statistic eps_norm_m from classic/5.0/src/Algorithms/PartBunch.cpp
                self.emit_norm[stepnum, :]       = s.attrs['#varepsilon'][()]
                # geometric emittance - m rad
                # the statistic eps_m from classic/5.0/src/Algorithms/PartBunch.cpp
                self.emit_geom[stepnum, :]  = s.attrs['#varepsilon-geom'][()]

                # HUH, these are backwards?!
                self.Bref[stepnum, :]       = s.attrs['E-ref'][()]
                self.Eref[stepnum, :]       = s.attrs['B-ref'][()]

                # identify particles that are part of original selection AND in this step
                _, pidsave, pidstep = np.intersect1d(pid0, s['id'][()], assume_unique=True, return_indices=True) 
                
                for idx, val in enumerate(('x', 'y', 'z', 'px', 'py', 'pz')):
                    self._particledata[stepnum, pidsave, idx] = s[val][()][pidstep]

            except (KeyError, IOError):
                print("Can't read step %d, truncating arrays" % (stepnum+1))
                for arr in (self.refs, self.reftheta, self.refz, self.t, 
                            self.Bref, self.Eref):
                    arr.resize(stepnum, refcheck=False)
#                 [a[:stepnum] for a in (self.refs, self.reftheta, self.refz, self.t, self.Bref, self.Eref)]
                self._particledata = self._particledata[:stepnum, :, :]
                Nstep = stepnum
                self.steps = self.steps[:Nstep]
                break
        
        (self.x, self.y, self.z, 
         self.px, self.py, self.pz) = [col.squeeze() for col in np.split(self._particledata, 6, axis=-1)]

        # TODO: particle with pid=0 is not particularly special and can be lost, so probably
        # remove these entirely
        self.x0  = self.x[:, [0]]
        self.y0  = self.y[:, [0]]
        self.z0  = self.z[:, [0]]
        self.px0 = self.px[:, [0]]
        self.py0 = self.py[:, [0]]
        self.pz0 = self.pz[:, [0]]
        self.p0 = np.linalg.norm((self.px0, self.py0, self.pz0), axis=0)

        self.xbar  = np.nanmean(self.x, axis=-1)
        self.ybar  = np.nanmean(self.y, axis=-1)
        self.zbar  = np.nanmean(self.z, axis=-1)
        self.pxbar  = np.nanmean(self.px, axis=-1)
        self.pybar  = np.nanmean(self.py, axis=-1)
        self.pzbar  = np.nanmean(self.pz, axis=-1)

        # the trace-space coordinate x'=dx/ds=(dx/dt)/(ds/dt) should be ~ px/p
        # self.xp = self.px / self.p0
        # self.yp = self.py / self.p0
        # self.zp = self.pz / self.p0

        # (x0, y0) might be nan, so use bar instead...
#         self.turnidx = turn_transitions(self.x0.reshape((Nstep,)), self.y0.reshape((Nstep,)))
        self.turnidx = turn_transitions(self.xbar, self.ybar)

        # ndarray shape (Nstep,) - number of particles alive at a given timestep """
        self.N = (np.isfinite(self._particledata).all(axis=-1)  # last axis is 6D phase-space, all must be finite
                                                 .sum(axis=-1)) # last axis is PID axis, sum to get number alive

        # There isn't a good reason to keep the file open at the moment
        h5file.close()

    @property
    def refx(self):
        return self.refr * np.cos(self.reftheta * np.pi/180.)

    @property
    def refy(self):
        return self.refr * np.sin(self.reftheta * np.pi/180.)

    @property
    def refp(self):
        """
        Reference momentum, in units of beta*gamma (dimensionless) and in
        global Cartesian coordinates
        """
        # OPAL's output of reference quantities can't be trusted
#         theta = self.reftheta * np.pi/180.
#         transp = (self.refpr[:, np.newaxis] * rhat(theta) + 
#                   self.refpt[:, np.newaxis] * phihat(theta))
#         return np.concatenate((transp, self.refpz[:, np.newaxis]), axis=1)
        return np.stack((self.pxbar, self.pybar, self.pzbar), axis=-1)

    @property
    def bg(self):
        return np.linalg.norm(self.refp, axis=1)

    @property
    def beta(self):
        """ Lorentz beta (v/c) at each step """
        # naturally, OPAL's output is sometimes zero for refp, and shouldn't be trusted...
#         bg = self.refp  # beta*gamma
#         bg = np.linalg.norm(bg, axis=1)
#         beta = np.sqrt((bg**2) / (1 + bg**2))
#         assert np.all((beta >= 0) &
#                       (beta < 1))
        bg = self.bg
        beta = np.sqrt((bg**2) / (1 + bg**2))
        return beta

    @property
    def gama(self):
        """ Lorentz at each step """
        return np.sqrt(1 / (1 - self.beta))

    @property
    def tns(self):
        """ Step times in ns """
        return self.t*1e9

    @property
    def refpx(self):
#         return self.refp[:, 0]
        return self.pbarx

    @property
    def refpy(self):
        return self.refp[:, 1]
        
    @property
    def dx(self):
        """ x-offset from reference position (m) """
        return self.x - self.refx[:, np.newaxis]

    @property
    def dy(self):
        """ y-offset from reference position (m) """
        return self.y - self.refy[:, np.newaxis]

    @property
    def dz(self):
        """ z-offset from reference position (m) """
        return self.z - self.refz[:, np.newaxis]

    @property
    def dr(self):
        return np.stack((self.dx, self.dy, self.dz), axis=-1)

    @property
    def dpx(self):
        """ offset from reference x-momentum (m) """
        return self.px - self.refpx[:, np.newaxis]

    @property
    def dpy(self):
        """ offset from reference y-momentum (m) """
        return self.py - self.refpy[:, np.newaxis]

    @property
    def dpz(self):
        """ offset from reference z-momentum (m) """
        return self.pz - self.refpz[:, np.newaxis]

    @property
    def r(self):
        """ The radius of each particle in the global cylindrical coordinate system (m) """
        return np.sqrt(self.x**2 + self.y**2)

    @property
    def th(self):
        """ The angle of each particle (rad) """
        return np.arctan2(self.y, self.x)
    
    def phase(self, refs=None):
        """
        Calculate the betatron phases (rad) at all steps
        
        Parameters
        ----------
        h : H5HutAccessor
            Simulation output file to use
        refs : ndarray (optional)
            reference axial coordinate to use. Must have shape `(Nstep,)`.
            If not given, the bunch average will be calculated for each step, and 
            the cumulative sum of the distances between these points will be used.

        Returns
        -------
        phase_x, phase_y
        """
        
        if refs is None:
            r = np.stack((self.xbar, self.ybar), axis=-1)
            dr = np.diff(r, axis=0)
            ds = np.linalg.norm(dr, axis=1)
            assert (ds > 0).all()  # s should be monotonically-increasing
        else:
            ds = np.ediff1d(refs)

        dx, xp, dy, yp, dz, zp = self.frenet_6D()
        beta_x, alfa_x, gama_x, emit_x = twiss(dx, xp)
        beta_y, alfa_y, gama_y, emit_y = twiss(dy, yp)

        phase_x = np.cumsum(ds/beta_x[1:])
        phase_y = np.cumsum(ds/beta_y[1:])
        return phase_x, phase_y
    
    def arc_mask(self, secnum, turnnum):
        """
        Return the step numbers of this trajectory that correspond to the given arc
        """
        assert 1 <= turnnum <= 16
        if turnnum == 1:
            turnstart = 0
            turnend = self.turnidx[0]
            if turnend < 10:
                raise ValueError('Something is almost certainly wrong, less than 10 steps in the first turn...')
        else:
            turnstart = self.turnidx[turnnum-2]
            turnend = self.turnidx[turnnum-1]
        turnx = self.x0[turnstart:turnend]
        turny = self.y0[turnstart:turnend]
        
        return turnstart + np.argwhere(in_sector(turnx, turny, secnum))[:, 0]
        
    @lru_cache(1)
    def frenet_6D(self):
        """
        Calculate the values in the Frenet-Serret frame of (dx, x', dy, y', ds, dps)

        NOTE: +y in this notation means the vertical coordinate (what OPAL/H5HutAccessor call +z), and
              +s means the longitundinal coordinate.

        Returns
        -------
        (dx, x', dy, y', ds, dps) - ndarrays of shape (Nstep, Npart) with the 6D coordinates of the particle
          in the Frenet-Serret frame:
            dx - horizontal distance from bunch mean (m) (+x means radially out)
            x' - horizontal transverse angle (rad)
            dy - vertical distance from bunch mean (m)  (+y means vertically up)
            y' - vertical transverse angle (rad)
            ds - longitudinal distance from bunch mean (m)  (+s means in the direction of rms momentum)
            dps - longitudinal momentum offset from bunch mean (dimensionless, multiples of beta*gama)
        """
        # step-by-step transformation into the Frenet frame
        # p0 lies in the +s direction (beam direction)
        # crossing this with the vertical direction gives radially OUT (+x)

        # per-step average momentum, ignoring lost particles
#         pxbar = np.nanmean(self.px, axis=1)[:, np.newaxis]
#         pybar = np.nanmean(self.py, axis=1)[:, np.newaxis]
#         pzbar = np.nanmean(self.pz, axis=1)[:, np.newaxis]
#         pbar = np.concatenate((pxbar, pybar, pzbar), axis=-1)
        # stack: (Nstep, Npart) -> (Nstep, Npart, 3)
        # nanmean: (Nstep, Npart, 3) -> (Nstep, 3)  (averaging over particles)
        pbar = np.stack((self.pxbar, self.pybar, self.pzbar), axis=-1)  # (Nstep, 3)
        pxbar, pybar, pzbar = np.split(pbar, 3, axis=-1)  # each array (Nstep, 1)
        normp = np.linalg.norm(pbar, axis=-1)[:, np.newaxis]  # (Nstep, 1)
        phat = (pbar/normp) # +s direction,  (Nstep, 3)

        assert np.isclose(np.linalg.norm(phat, axis=1), 1.0).all(), "Something is wrong, not all values of phat have norm ~ 1.0"

        # NOTE that this notation is different from the global coordinate system
        # it is conventional to call the vertical direction +y, the
        # radial/transverse +x, and the axial +z/+s
        yhat = np.array([0, 0, 1])
        xhat = np.cross(phat, yhat)

        # per-step average position, ignoring lost particles
        rbar = np.nanmean(np.stack((self.x, self.y, self.z), axis=-1), axis=1)
        xbar, ybar, zbar = np.split(rbar, 3, axis=-1)

        # shape (Nstep, Npart), NaN for lost particles
        dx =  self.x - xbar
        dy =  self.y - ybar
        dz =  self.z - zbar
        dpx = self.px - pxbar
        dpy = self.py - pybar
        dpz = self.pz - pzbar

        # shape (Nstep, 1, 3) for the broadcast below
        xhat = xhat[:, np.newaxis, :]
        phat = phat[:, np.newaxis, :]

        # stack into vectors, then project into the Frenet basis (spanned by [phat, xhat, yhat])
        dr = np.stack((dx, dy, dz), axis=-1)  # shape (Nstep, Npart, 3)
        # results in shape (Nstep, Npart)
        dx = (dr * xhat).sum(axis=-1)
        dy = (dr * yhat).sum(axis=-1)
        ds = (dr * phat).sum(axis=-1)

        dp = np.stack((dpx, dpy, dpz), axis=-1)  # shape (Nstep, Npart, 3)
        # shape (Nstep, Npart)
        dpx = (dp * xhat).sum(axis=-1)
        dpy = (dp * yhat).sum(axis=-1)
        dps = (dp * phat).sum(axis=-1)

        # convert to angles i' ~ p_i/|p|
        xp = dpx / normp
        yp = dpy / normp

        return (dx, xp, dy, yp, ds, dps)


    def poincareplot(self, steps, extralabel=lambda step: '', lims=None, colorbar=True):
        """
        Make a set of Poincare plots for a given step of sequence thereof.

        Parameters
        ----------
        steps : sequence of int or a single integer
            The step(s) to plot
        extralabel : callable, optional 
            A callable with signature `extralabel(step)` that returns an extra
            string label to add to the title for a given step number
        lims : dict, optional 
            A dictionary of limits for the Poincaré plots, with keys `'xy.h',
            'xy.v', 's.h', 's.v'`, and values corresponding to the magnitude of
            the (symmetric) axis limits on the respective plots. The transverse
            plots share limits to ensure that they are always comparable, and
            because we expect roughly axisymmetric beams.
        colorbar : bool, optional
            Boolean indicating whether or not to draw colorbars

        Returns
        -------
        poincarefig : Figure
        """
        try:
            iter(steps)
        except TypeError:
            steps = [steps]

        dx, xp, dy, yp, ds, dps = self.frenet_6D()
        hvar_x = 1e3*dx[steps, :]
        vvar_x = 1e3*xp[steps, :]
        hvar_y = 1e3*dy[steps, :]
        vvar_y = 1e3*yp[steps, :]
        hvar_s = 1e3*ds[steps, :]
        vvar_s = dps[steps, :]
#         sxy_h = max(np.nanstd(hvar_x, axis=1).max(), np.nanstd(hvar_y, axis=1).max())
#         sxy_v = max(np.nanstd(vvar_x, axis=1).max(), np.nanstd(vvar_y, axis=1).max())
#         ss_h = np.nanstd(hvar_s, axis=1).max()
#         ss_v = np.nanstd(vvar_s, axis=1).max()
        sxy_h = max(np.nanstd(hvar_x, axis=1).mean(), np.nanstd(hvar_y, axis=1).mean())
        sxy_v = max(np.nanstd(vvar_x, axis=1).mean(), np.nanstd(vvar_y, axis=1).mean())
        ss_h = np.nanstd(hvar_s, axis=1).mean()
        ss_v = np.nanstd(vvar_s, axis=1).mean()
        _lims = {
                'xy.h': 3*sxy_h,
                'xy.v': 3*sxy_v,
                's.h':  3*ss_h,
                's.v':  3*ss_v,
        }
        if lims: 
                _lims.update(lims)

        N = len(steps)
        if colorbar:
            Ncols = 9
        else:
            Ncols = 3

        w_hb = 5
        h_hb = 6
        w_cb = 1
        cb_pad = 1
        w_fig = 3*w_hb + int(Ncols>3)*(w_cb + cb_pad)
        h_fig = N*h_hb
        if colorbar:
            widths = [8, 1, 3, 8, 1, 3, 8, 1, 3]
        else:
            widths = [1, 1, 1]
        poincarefig = plt.figure(figsize=(w_fig, h_fig), facecolor='white')
        gs = GridSpec(nrows=N, ncols=Ncols, hspace=0.2, width_ratios=widths, figure=poincarefig)
        for row, step in enumerate(steps):
            hsl = slice(row*h_hb, (row+1)*h_hb)
            if colorbar:
                ax_x =  plt.subplot(gs[row, 0])
                cax_x = plt.subplot(gs[row, 1])
                ax_y =  plt.subplot(gs[row, 3])
                cax_y = plt.subplot(gs[row, 4])
                ax_s =  plt.subplot(gs[row, 6])
                cax_s = plt.subplot(gs[row, 7])
            else:
                _w = w_fig//3
                ax_x = plt.subplot(gs[row, 0])
                ax_y = plt.subplot(gs[row, 1])
                ax_s = plt.subplot(gs[row, 2])
            ax_x.set_xlabel(r"$\Delta x$ (mm)")
            ax_x.set_ylabel(r"$x'$ (mrad)")
            hlim, vlim = _lims['xy.h'], _lims['xy.v']
            hb_x = ax_x.hexbin(hvar_x[row], vvar_x[row], extent=[-hlim, hlim, -vlim, vlim])
            if colorbar:
                Colorbar(mappable=hb_x, ax=cax_x)

            ax_y.set_xlabel(r"$\Delta y$ (mm)")
            ax_y.set_ylabel(r"$y'$ (mrad)")
            hb_y = ax_y.hexbin(hvar_y[row], vvar_y[row], extent=[-hlim, hlim, -vlim, vlim])
            ax_y.set_title(f't={self.tns[step]:.2f} ns {extralabel(step)}')
            if colorbar:
                Colorbar(mappable=hb_y, ax=cax_y)

            ax_s.set_xlabel(r"$\Delta s$ (mm)")
            ax_s.set_ylabel(r"$\Delta p_s (\beta\gamma)$")
            hlim, vlim = _lims['s.h'], _lims['s.v']
            hb_s = ax_s.hexbin(hvar_s[row], vvar_s[row], extent=[-hlim, hlim, -vlim, vlim])
            if colorbar:
                Colorbar(mappable=hb_s, ax=cax_s, )

        if not colorbar:
            gs.tight_layout(poincarefig)
                
        return poincarefig

    
    def plot_trace(self, step, which, kind='marker', ax=None, *args, **kwargs):
        """
        Given a step number, plot one of the transverse trace spaces

        Params
        ------
        step - step number to plot
        which - "xx'", "yy'", or "ss'" to indicate which trace space to plot
        kind - 'marker' or 'hex'
            controls whether the plot uses unfilled circular markers (default) or hexbin()
        ax (optional) - matplotlib Axes object to use to plot. Defaults to gca()

        Notes
        -----
        *args, **kwargs are passed to each plotting function (plot() and hexbin())
        """
        if ax is None:
            fig = plt.figure(figsize=(16, 12), facecolor='white')
            ax = plt.gca()
        else:
            fig = ax.figure

        if which == "xx'":
            hvar = dx[step, :]
            vvar = xp[step, :]
            xlabel = "x (m)"
            ylabel = "x' (rad)"
            beta, alfa, gama, emit = [val[step] for val in twiss(dx, xp)]
            title += f' $\\beta_x={beta:.2f}$ m'
        elif which == "yy'":
            hvar = dy[step, :]
            vvar = yp[step, :]
            xlabel = "y (m)"
            ylabel = "y' (rad)"
            beta, alfa, gama, emit = [val[step] for val in twiss(dy, yp)]
            title += f' $\\beta_y={beta:.2f}$ m'
        elif which == "ss'":
            hvar = dz[step, :]
            vvar = zp[step, :]
            xlabel = "s (m)"
            ylabel = "s' (rad)"
        elif which == 'xy':
            raise NotImplemented
        else:
            raise ValueError(f"Plot type '{which} not supported")

        if kind == 'marker':
            ax.plot(hvar, vvar, 'ko', mfc='none')
        elif kind == 'hex':
            gridsize = kwargs['gridsize'] if 'gridsize' in kwargs else NBINS
            mappable = ax.hexbin(hvar, vvar, gridsize=gridsize)
            plt.colorbar(mappable, ax=ax)
        else:
            raise TypeError("'kind' must be either 'marker' or 'hex' ")

        ax.set_title(title) 
        ax.set_xlabel(xlabel)
        ax.set_ylabel(ylabel)

        # plot RMS "window"
        if which in ("xx'", "yy'"):
            XLIM = plt.xlim()
            YLIM = plt.ylim()
            winH = np.sqrt(beta * emit)
            winV = np.sqrt(gama * emit)
            ax.vlines([-winH, winH], -1, 1, 'r', '--')
            ax.hlines([-winV, winV], -1, 1, 'r', '--')
            a, b = l_axes(alfa, beta, gama, emit)
            ang = angle(alfa, beta, gama, emit)
            t = np.linspace(0, 2*np.pi, 100)
            xe = a*np.cos(t)
            ye = b*np.sin(t)
            xe, ye = (xe*np.cos(ang) + ye*np.sin(ang), xe*np.sin(ang) - ye*np.cos(ang))
            ax.plot(xe, ye, 'r-')
            ax.set_xlim(XLIM)
            ax.set_ylim(YLIM)

        return fig
    
    def __enter__(self):
        return self

    def __exit__(self, *args):
        self.__del__(args)

    def __del__(self, *args):
        try:
            self._h5.close()
        except ValueError:
            pass

    def __len__(self):
        return len(self.steps)


def rhat(theta):
    r""" 
    Returns the unit vector $\hat{r} = cos(\theta) \hat{x} + sin(\theta) \hat{y}$
    
    theta - angle in radians
    """
    return np.stack((np.cos(theta), np.sin(theta)), axis=1).squeeze()

def phihat(theta):
    r""" 
    Returns the unit vector $\hat{phi} = -sin(\theta) \hat{x} + cos(\theta) \hat{y}$
    
    theta - angle in radians
    """
    return np.stack((-np.sin(theta), np.cos(theta)), axis=1).squeeze()

def l_axes(alfa, beta, gama, emit):
    u"""
    Given parameters (α, β, γ, ε) for a trace-space ellipse, calculate the length of each axis
    
    Notes
    -----
    Taken unceremoniously from http://mathworld.wolfram.com/Ellipse.html
    """
    g = -emit
    a = gama
    b = alfa
    c = beta
    
    numerator = 2*(g*b**2 - a*c*g)
    
    denom = (b**2 - a*c) * (np.sqrt((a-c)**2 + 4*b**2) - (a+c))
    
    La = np.sqrt(numerator/denom)
    
    denom = (b**2 - a*c) * (-np.sqrt((a-c)**2 + 4*b**2) - (a+c))
    
    Lb = np.sqrt(numerator/denom)
    
    return La, Lb

def angle(alfa, beta, gama, emit):
    u"""
    Given parameters (α, β, γ, ε) for a trace-space ellipse, calculate the angle of rotation of the ellipse (from major along +x) 
     
    Notes
    -----
    Taken unceremoniously from http://mathworld.wolfram.com/Ellipse.html
    """
    a = gama
    b = alfa
    c = beta
    if np.isclose(alfa, 0):
        if a < c:
             return 0
        else:
             return np.pi
            
    assert((a-c)/(2*b) != 0)
    
    # note: numpy does not have arccot(), but if z != 0, arccot(z) = arctan(1/z)
    ang = 1./2 * np.arctan((2*b)/(a-c))
    if a <= c:
        return ang 
    else:
        return np.pi/2 + ang
    
def rmsemit(x, xp):
    """ Given a trace space (x, xp), calculate the RMS emittance """
    x = np.asarray(x)
    xp = np.asarray(xp)
    xx = (x**2).mean()
    xxp = (x*xp).mean()
    xpxp = (xp**2).mean()
    return np.sqrt(xx*xpxp - xxp**2)

def twiss(x, xp):
    """
    Given a trace space (x, xp) (in the Frenet frame), calculate the 
    RMS values of beta_x, alfa_x, gama_x, emit_x, according to:

        $$$
        emit = \sqrt(<x^2> * <x'^2> - <x x'>^2)
        beta = <x^2> / emit
        alfa = -<x x'> / emit
        gama = <x' x'> / emit
        $$$

    Notes
    -----
    NaN values in either `x` or `xp` are ignored.
    The units of the returned Twiss parameters will depend on the input, but
    if `x` is given in meters and `xp` is given in radians, then beta will be
    in meters and emit will be in m*rad.

    Returns
    -------
    (beta, alfa, gama, emit)
    """
    # "centering" the distribution so that <x> = <x'> = 0 exactly by construction
    x -= np.nanmean(x, axis=1)[:, np.newaxis]
    xp -= np.nanmean(xp, axis=1)[:, np.newaxis]
    
    # expectation values of <x^2> <x'^2>, <xx'>
    xx = np.nanmean(x**2, axis=1)
    xpxp = np.nanmean(xp**2, axis=1)
    xxp = np.nanmean(x*xp, axis=1)

    emit = np.sqrt(xx*xpxp - xxp**2)
    beta = xx / emit
    alfa = -xxp / emit
    gama = xpxp / emit
    
    return (beta, alfa, gama, emit)


def turn_transitions(x, y, angle=0.0):
    r"""
    return array of indices of the arrays x, y indicating where the given particle (column) crossed
    the line defined by theta=angle (rad) (default = 0) in the last step.

    Parameters
    ----------
    x, y - 1d array_like (nturns,)
        of x and y coordinates
    angle - float
        defining angle (rad) for the transition line
    
    Returns
    -------
    indices - tuple (nparticles)
        indices of the crossing step for each particle

    Notes
    -----
    any `angle` can be provided, but the calculation will be done modulo 2*pi
    """
    assert np.ndim(x) == 1 and np.ndim(y) == 1, "input must be 1d"
    theta = np.arctan2(y, x)
    return argrelmin((theta + angle) % (2*np.pi))[0]
