"""
    Utilities for dealing with H5Hut files generated by OPAL

"""
import os
from datetime import datetime

import h5py
import numpy as np


class H5HutAccessor():
    """
    An accessor class that loads an H5Hut file and stores the data in  more 
    useful numpy arrays

    Attributes
    ----------
    t : float
        global time (sec)
    theta : float
        angles of reference (pid=0) particle (deg)
    s : float
        s coordinates of reference (pid=0) particle (m)
    Bref : float ndarray with shape (Nstep, 3)
        Magnetic field seen by reference (pid=0) particle (T)
    Eref : float ndarray with shape (Nstep, 3)
        Electric field seen by reference (pid=0) particle (MV/m)
    x, y, z : float ndarray with shape (Nstep, Nparticles)
        spatial coordinates (global frame) of all particles (m)
    px, py, pz : float ndarray with shape (Nstep, Nparticles)
        momentum coordinates (global frame) of all particles (units of beta*gamma)

    """

    def __init__(self, fn, stride=1, minstep=0, maxstep=-1):
        """
        Parameters
        ----------
        fn : str
            path to the H5Hut file to process
        stride : int, optional
            stepsize (default: 1) between adjacent steps to load. Useful if the 
            user wants to examine a very fine file without using ALL the 
            temporal resolution.
        minstep : int, optional
            phase dump (not integrator!) step (default: 0) to begin processing 
            from
        mmaxstep : int, optional 
            maximum phase dump (not integrator!) step (default: -1) to process

        Notes
        -----
        The HDF5 will be closed after initialization.
        """
        self._h5 = h5file = h5py.File(fn, 'r')
        self.modified_time = datetime.fromtimestamp(int(os.stat(fn).st_mtime))
        self.steps = sorted([k for k in h5file.keys() if k.startswith('Step#')][minstep:maxstep:stride], key=lambda n: int(n.split('#')[-1]))

        Nstep = len(self.steps)

        assert h5file[self.steps[0]].attrs['NumBunch'] == 1, "Only single-bunch files supported"
        # NOT correct for injected beams!
        Npart = h5file[self.steps[0]]['id'].size
        
        # iterating steps is relatively expensive, so let's establish arrays to store data
        # the default datatype is np.float64 (8 bytes per value), so 8 * (Nstep*(3+6+6*Npart)) bytes total
        # (~ 80 MB for 1000 particles and 1667 steps; attrs data should be kbytes worth at O(Nstep))
        self.s, self.theta, self.t = [np.full((Nstep,), np.nan) for _ in range(3)]
        self.Bref, self.Eref = [np.full((Nstep, 3), np.nan) for _ in range(2)]
        self._particledata = np.full((Nstep, Npart, 6), np.nan)

        for stepnum, step in enumerate(self.steps):
            try:
                pid = h5file[step]['id'][()]
                self.s[stepnum] = h5file[step].attrs['SPOS'][()]
                self.theta[stepnum] = h5file[step].attrs['REFTHETA'][()]
                self.t[stepnum] = h5file[step].attrs['TIME'][()]
                self.Bref[stepnum, :] = h5file[step].attrs['B-ref'][()]
                self.Eref[stepnum, :] = h5file[step].attrs['E-ref'][()]
                
                self._particledata[stepnum, pid, 0] = h5file[step]['x'][()]
                self._particledata[stepnum, pid, 1] = h5file[step]['y'][()]
                self._particledata[stepnum, pid, 2] = h5file[step]['z'][()]
                self._particledata[stepnum, pid, 3] = h5file[step]['px'][()]
                self._particledata[stepnum, pid, 4] = h5file[step]['py'][()]
                self._particledata[stepnum, pid, 5] = h5file[step]['pz'][()]
            except KeyError, IOError:
                print("Can't read step %d, truncating arrays" % (stepnum+1))
                self.s, self.theta, self.t, 
                self.Bref, self.Eref = [a[:stepnum] for a in self.s, self.theta, self.t, self.Bref, self.Eref]
                self._particledata = self._particledata[:stepnum, :, :]
                break
        
        # there could possibly be some memory duplication issue here if copies 
        # are created instead of views, but I *think* numpy should always give a view.
        self.x = self._particledata[:, :, 0]
        self.y = self._particledata[:, :, 1]
        self.z = self._particledata[:, :, 2]
        self.px = self._particledata[:, :, 3]
        self.py = self._particledata[:, :, 4]
        self.pz = self._particledata[:, :, 5]

        # There isn't a good reason to keep the file open at the moment
        h5file.close()

    def __enter__(self):
        return self

    def __exit__(self, *args):
        self.__del__(args)

    def __del__(self, *args):
        try:
            self._h5.close()
        except ValueError:
            pass

    def __len__(self):
        return len(self.steps)
